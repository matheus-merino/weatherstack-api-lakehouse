{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e596cec0-e523-4371-b05c-cfb70b3e7aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, to_date, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faaf02ba-143a-4e26-9942-2cd1f68042f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining paths\n",
    "landing_zone_path = '/mnt/data/landing/weather'\n",
    "today_string = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "landing_path_today = f'{landing_zone_path}/{today_string}'\n",
    "print('Todays Landing Path: ', landing_path_today)\n",
    "\n",
    "bronze_table_path = '/mnt/data/bronze/weather'\n",
    "bronze_table_name = 'weather.bronze_weather_raw'\n",
    "\n",
    "# Defining API info\n",
    "api_key = dbutils.secrets.get(scope = 'weather-keys', key = 'api-key')\n",
    "endpoint = 'https://api.weatherstack.com/current'\n",
    "cities = ['Gramado, Brazil', 'Punta Del Este, Uruguay', 'Punta Arenas, Chile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed1e5f36-3e30-4d1f-80d5-a7a9ce694ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    response = requests.get(endpoint, params={'access_key': api_key, 'query': city})\n",
    "    data = response.json()\n",
    "\n",
    "    city_str = city.replace(' ', '_').replace(',', '').lower()\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f'{city_str}_{timestamp_str}.json'\n",
    "    output_path = f'{landing_path_today}/{file_name}'\n",
    "\n",
    "    dbutils.fs.put(output_path, json.dumps(data), overwrite=True)\n",
    "    print(f'File {file_name} written to {landing_path_today}')\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14fdf7d4-54e3-4ba8-928d-c6382e34465a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files_in_landing = dbutils.fs.ls(landing_path_today)\n",
    "\n",
    "if not files_in_landing:\n",
    "    dbutils.notebook.exit(\"No files to process in landing zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce76626-eea9-440d-874e-288e445149f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df = spark.read.text(landing_path_today)\n",
    "\n",
    "bronze_df = raw_df.withColumnRenamed('value', 'raw_payload')\\\n",
    "                    .withColumn('ingestion_timestamp', current_timestamp())\\\n",
    "                    .withColumn('ingestion_date', to_date(col('ingestion_timestamp')))\\\n",
    "                    .withColumn('source_path', col('_metadata.file_path'))\\\n",
    "                    .withColumn('source_file_name', col('_metadata.file_name'))\\\n",
    "                    .withColumn('last_modified', col('_metadata.file_modification_time'))\n",
    "\n",
    "display(bronze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cea5ecb-d897-4834-bc2a-044459740ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df.write.format(\"delta\").mode(\"append\").save(bronze_table_path) # Could also use .option(\"mergeSchema\", \"true\") for schema evolution\n",
    "print(f\"{bronze_df.count()} rows added to {bronze_table_name}.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-ingest-to-bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
